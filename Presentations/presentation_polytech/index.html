<!doctype html>
<html>
  <head>
    <link rel="stylesheet" href="style.css">
	<link rel="stylesheet" href="timeline.css">
	
 </head>

  <body>
  
  <section>

<div id="main-text">

<!-- qu'attendez-vous-->
<ul id='timeline'>
  <li class='work'>
    <input class='radio' id='work1' name='works' type='radio' >
    <div class="relative">
      <label for='work1'>Attentes ?</label>
    </div>
    <div class='content'>
	
    </div>
  </li>
  
   <li class='work'>
    <input class='radio' id='work2' name='works' type='radio' >
    <div class="relative">
      <label for='work2'>Déroulement</label>
    </div>
    <div class='content'>
      <p>
- présentations
<br>- Qu'est-ce que la réalité virtuelle (RV) ?
<br>- Quels intérêts d'utiliser la RV (dans une perspective éco) ?
<br>- Considérations techniques (focus sur les casques)
<br>- la RV dans les Sciences Humaines et Sociales (SHS)
<br>- Qu'est-ce que la conception centrée utilisateur ?
<br>- Aspects pratiques pour la conception d'environnement virtuel (EV)
      </p>
    </div>
  </li>
  
  
  
  
  
  
  
  
  
 <!-- Présentation FF --> 
  <li class='work'>
    <input class='radio' id='work3' name='works' type='radio' >
    <div class="relative">
      <label for='work3'>Présentation</label>
    </div>
    <br><br>
	  <div class="container">
	<div class="table">
		<div class="table-content">	
			<div class="table-row">	
				<div class="table-data"> <video class="vidH"; id="myVid1" controls><source src="contenu/these1.mp4" type="video/mp4"></video>  </div>			
				<div class="table-data"><video class="vidL"; id="myVid2"controls><source src="contenu/toutpasse.mp4" type="video/mp4"></video>    </div>

			</div>
			<div class="table-row">
				<div class="table-data"><br></div>
			</div>
			<div class="table-row">
				<div class="table-data"><video class="vidL"; id="myVid4"controls><source src="contenu/augmentedworkspace.mp4" type="video/mp4"></video>   </div>			
				<div class="table-data"><video class="vidL"; id="myVid6"controls><source src="contenu/acceptance.mp4" type="video/mp4"></video></div>
			</div>
				<div class="table-row">
				<div class="table-data"><br></div>
			</div>
				<div class="table-row">
				<div class="table-data"><video class="vidL"; id="myVid5"controls><source src="contenu/geolocra.mp4" type="video/mp4"></video> </div>
	</div>
		</div>	
	</div>
</div>
  </li>
  
  
  
  
  
  


  
  
  
 <!-- Présentation P2AC -->
   <li class='work'>
    <input class='radio' id="work4" name='works' type='radio' >
    <div class="relative">
  <label for='work4';>USERLAB P2AC</label>
    </div>
<br><br><br><br>
<img class ="titeimg"; src="contenu/OIC.png"> </img>
<img class ="titeimg"; src="contenu/logo_region.png"> </img>
<img class ="titeimg"; src="contenu/logo_confluences.png"> </img>
<img class ="titeimg"; src="contenu/logo_ua.png"> </img>
<br><br><br><br>
3 UserLabs de la région Pays de la Loire
<br> Spécialisée en <b>Sciences Humaines et Sociales</b> (psychologie, marketing, économie, etc.)
<br> Compétences et outils (informatiques, électroniques et numériques) pour l'analyse des <b>comportements humains</b>
<br> <b> Conçoit</b> des environnements contrôlés (réels, virtuels et mixtes)
<br> <b>Mesure</b> la réaction des utilisateurs (comportementale, physiologique, cognitive, etc.)
<br><br><br><br>
 <div class="container">
	<div class="table">
		<div class="table-content">	
			<div class="table-row">	
				<div class="table-data"> Psychologie Cognitive <br><br> Dépasser les tests "papiers crayons" <br> pour analyser le fonctionnement cognitif de patient <br> Complémentarité des données comportementales <br>(Eyetracking)  <video class="vidL"; id="myVid7" controls><source src="contenu/sep.mp4" type="video/mp4"></video>  </div>			
				<div class="table-data"> Psychologie Sociale <br><br> Standardiser des environnements <br> entrainement aux softs skills <br>Suivi et caractérisation de la performance <br> <br>  <video class="vidL"; id="myVid8" controls> <source src="contenu/greta.mp4" type="video/mp4"></video> </div>
			</div>
			<div class="table-row">
				<div class="table-data"></div>			
				<div class="table-data"></div>
			</div>
			<div class="table-row">
				<div class="table-data">Tourisme & Culture <br><br>Permettre des situations irréalisables <br> Enregistrer des données physiologiques <br>(FC, Conductance cutanée) <video class="vidL"; id="myVid9"controls><source src="contenu/granem.mp4" type="video/mp4"></video> </div>			
				<div class="table-data">Marketing & Economie<br><br> Augmenter le réalisme <br> Evaluer de nouvelles variables comportementales <br><br><video class="vidL"; id="myVid10"controls><source src="contenu/supermarket.mp4" type="video/mp4"></video> </div>
			</div>
		</div>	
	</div>
</div>
</li>
  
  

<!-- Réalité virtuelle -->
   <li class='work'>
    <input class='radio' id='work5' name='works' type='radio' >
    <div class="relative">
      <label for='work5'>RV ?</label>
    </div>
<br><br><br><br>
 <img src="contenu/continuum.png"> </img> 
  <p class="citation"; style="text-align:center">A taxonomy of mixed reality visual displays. Milgram & Kishino</p>
<br><br><br><br>
 <img src="contenu/TheorierealitevirtuelleLivre.jpg"> </img> 
 <p class="citation"; style="text-align:center">Un livre référence (dispo à la BU).</p>

 <br>
 <br>
<i>Définition : Permettre à une personne, une activité sensorimotrice et cognitive dans un monde artificiel.... </i>
<br>
- symbolique, réel, imaginaire (Lacan)
<br>- Sensorimoteur
<br>- Cognitif (processus...traitement de l'information..)
<br><br><br><br>
<br> Un modèle
<br><br>
<img src="contenu/3i.jpg"> </img> 
 <p class="citation"> Perception, immersion et interactions sensorimotrices en environnement virtuel, Malika AUVRAY & FUCHS </p>
 <!-- vous intervenez au niveau intermédiaire-->
<br>
<br>
<br>
- Interaction temps réel : objectif
<br>- Immersion : subjectif ou objectif ?
<br>
<br>
<br>
Pour aller plus loin :  

<br>
 - Interface motrice seulement ?
 <video class="vidL"; id="myVid3"controls><source src="contenu/contemplativeloneliness.mp4" type="video/mp4"></video>  
<br>
<br>



VR or not VR ?
<br>
<br>
 <video class="vidL"; id="myVid11"controls><source src="contenu/Magnavox.mp4" type="video/mp4"></video>  
  <li class='work'>
    <input class='radio' id='work6' name='works' type='radio' >
    <div class="relative">
      <label style="font-size: 1vw;"; for='work6' >Réponse </label>
    </div>
    <div class='content'>
	<p>
	--> suivi des yeux, recouvre la vision
	</p>
    </div>
  </li>

 <video class="vidL"; id="myVid12"controls><source src="contenu/video360.mp4" type="video/mp4"></video> 
   <li class='work'>
    <input class='radio' id='work7' name='works' type='radio' >
    <div class="relative">
      <label style="font-size: 1vw;"; for='work7' >Réponse </label>
    </div>
    <div class='content'>
	<p>
--> pas d'interactions	</p>
    </div>
  </li>

 <video class="vidL"; id="myVid13"controls><source src="contenu/rv_withoutvision.mp4" type="video/mp4"></video>  
    <li class='work'>
    <input class='radio' id='work8' name='works' type='radio' >
    <div class="relative">
      <label style="font-size: 1vw;"; for='work8' >Réponse </label>
    </div>
    <div class='content'>
	<p>
--> la définition	</p>
    </div>
  </li>

</li>






 <li class='work'>
    <input class='radio' id='work9' name='works' type='radio' >
    <div class="relative">
      <label for='work9'>Presence & Immersion</label>
    </div>

<br><br><br><br>
<img src="contenu/Immersion and Presence.jpg"> </img> 

"...immersion is a "technology-related", objective aspect of VEs, presence is a psychological, perceptual and cognitive consequence of immersion.
Presence is thought of as the psychological perception of "being in" or "existing in" the VE in which one is immersed."

<br><br><br><br>

La mesure (subjective) 
<br><br> Quelques articles :
<br> - Measuring presence in virtual environments: A presence questionnaire. 
<br> - Presence: Teleoperators and Virtual Environments.
<br>- Using Presence Questionnaires in Virtual Reality.

<img src="contenu/items quest presence.jpg"> </img> 
 <p class="citation"; style="text-align:center">Quelques items d'un questionnaire évaluant la présence.</p>
<br><br>

<img src="contenu/questimmersionpresence.jpg"> </img> 
 <p class="citation"; style="text-align:center">Les sous-échelles de la présence.</p>


 <!--lourd, vous juste vérifier, pas dans une démarche scientifique-->

<br><br><br><br>
La mesure (objective) --> exemple analyse physiologique
<br><br>
<img src="contenu/physiologymeasure_presence.jpg"> </img> <!--indirecte mais dynamique et ne ment pas-->
 <p class="citation"; style="text-align:center">Immersion and Presence. Daniel R Mestre.</p>

<br>
<br><br>
La mesure (objective) --> exemple analyse comportementale
<br><br>
" One first example of such behavior is oculomotor behavior. Ocular behaviors have
long been suggested as presence measures [33]. Measures of visual system
behavior may provide a wealth of information regarding attention, alertness and
arousal., eye-trackers, and electro-oculograms (EOGs) have the potential to be
useful tools in the isolation of presence invoking stimuli. "

<br><br><br><br>
Conclusion :
Valider la presence --> objectif de l'application (apprentissage, traitement phobie ...) <!-- si la personne ne réagit pas physiologiquement et comportementalement (regarde, etc) dans l'ev que dans la vrai vie on peut se poser la question de l'utilité ??-->


</li>







 
 <br><br><br><br>
  <li class='work'>
    <input class='radio' id='work10' name='works' type='radio' >
    <div class="relative">
      <label for='work10'>A quoi sert la RV ?</label>
    </div>

 <br><br><br><br>
 <!-- com du dessus fait la transition avec l'utilité de la VR : supposition que votre app est bien developpé, que la personne est dans un état de présence et qu'elle ne va pas bégère : on verra ça plus tard -->
 
Cycle gartner
<br><br>
<img src="contenu/gartner2017.jpg"> </img>
<img src="contenu/gartner2020.png"> </img> <!-- le chemin est long --> 

 <!--la rv va pas sauver le monde ni remplacer le monde actuel (metaverse - ready player one) -->
 <br><br><br><br>
 La RV va sauver le monde ?
 <img src="contenu/metaverseGardian.jpg"> </img> 
  <p class="citation"; style="text-align:center">Un article dans "the Guardian"</p>

 <br><br>
  <video class="vidL"; id="myVid14"controls><source src="contenu/readyp1.mp4" type="video/mp4"></video>  
 <p class="citation"; style="text-align:center">Extrait de "Ready player One". Steven Spielberg</p>

 
 Alors ça sert à quoi - exemple pour l'apprentissage ?
<!--neanmoins ça permet de faire certaine chose directement applicable : mais quoi ??? -->

<br><br>

    <li class='work'>
    <input class='radio' id='work11' name='works' type='radio' >
    <div class="relative">
      <label style="font-size: 1vw;"; for='work11' >Réponse </label>
    </div>
    <div class='content'>
	<p>
<!-- interet de la VR -->
<br>-	Créer des situations non réalisables en réel
<br>-	Standardiser des environnements
<br>- 	Representer / conceptualiser des phénomènes / données, etc.
<br>-	Augmenter le réalisme
<br>-	Enregistrer des infos temps réels (physio, comportement, etc.)
<br>- 	Se placer à differents points de vue
<br>-	Rejeu de données	
</p>
    </div>
  </li>





 <li class='work'>
    <input class='radio' id='work11' name='works' type='radio' >
    <div class="relative">
      <label for='work11' >Vie économique </label>
    </div>
  <br><br><br><br>

  EN + d'apprendre : gestes techniques, soft-skills, etc.
   <video  class="vidL"; id="myVid15"; controls mutedcontrols><source src="contenu/apprendre.mp4" type="video/mp4"></video>  

  <br><br>
  Divertir : jeu vidéo, cinéma, visite culturelle/scientifique, pornographie, monde virtuel/social, librairie, etc.
    <video class="vidL"; id="myVid16"; controls mutedcontrols><source src="contenu/divertir.mp4" type="video/mp4"></video>  

  <br><br>
  Comprendre :  evenements physiques, des concepts scientifiques, prise de decision métadonnée, etc...
  <video class="vidL"; id="myVid17"; controls mutedcontrols><source src="contenu/comprendre.mp4" type="video/mp4"></video>  
 
  <br><br>
  Concevoir : architecture, art (créer ou nouvel art-film interactif), véhicule (ergonomie), etc.
    <video class="vidL"; id="myVid18"; controls mutedcontrols><source src="contenu/concevoir.mp4" type="video/mp4"></video>  

  <br><br>
  "Défendre" : entrainement militaire
      <video class="vidL"; id="myVid19"; controls mutedcontrols><source src="contenu/defendre.mp4" type="video/mp4"></video>  
  
  <br><br>
  Contrôler : supervisation de projet, robot précis, etc.
        <video class="vidL"; id="myVid20"; controls mutedcontrols><source src="contenu/controller.mp4" type="video/mp4"></video>  
 
 <br><br>
  "soigner / changer" ? : traitement post traumatique, phobie, anxiété, Alzheimer, prothéus effect – drogue , rehabilitation physique Parkinson, douleur et anesthésie
  <br>
  <br>"Spiritualiser" : pratiquer un culte
  
  <br><br>
    Apparté R&D --> Comprendre les comportements :
<br>- cognition chez sujets sains et pathologiques
<br>- achat (hédonique)
<br> - apprentissage (feedback, gamification, etc.) 
<br>- changement d'état (douleur, post-traumatique, tester/valider des méthodologies etc.) 
<br><br>Intéret --> "cost-effective tool to study and replicate interactions in a controlled environment"

<!-- application dans le monde éco, social de la santé (SEP, Cerema (ecran vers RV), marketing, etc..  -->
 
   <video class="vidL"; id="myVid21"controls><source src="contenu/sep.mp4" type="video/mp4"></video>  
  
  <video class="vidL"; id="myVid22"controls><source src="contenu/greta.mp4" type="video/mp4"></video>  
  
  <video class="vidL"; id="myVid23"controls><source src="contenu/cerema.mp4" type="video/mp4"></video>  

</li>
 
 
 
 <br><br><br>
  
 
   <li class='work'>
    <input class='radio' id='work12' name='works' type='radio' >
    <div class="relative">
      <label for='work12'>Technique (focus casque)</label>
    </div>

 <p>
 
   <!-- Technique -->
  <br> <br> <br> <br>
 Une vision holistique (hardware, software, humain)   <!-- ou est-ce que vous intervenez ? au niveau logiciel en prenant en compte l'humain -->
 <br> <br> 
 <img src="contenu/sensory_motorinterface.bmp"> </img>
  <p class="citation"; style="text-align:center">réf perdue.</p>

 <br> <br>
<br> <br>
L'humain --> multifactoriel & au centre des developpements : 
<br> - quel est mon but en tant que developpeur/chef de projet (divertir, etc.)
<br> - quel est mon public cible (sains ?)
<br> <br>
<img src="contenu/model humain.jpg"> </img>
  <p class="citation"; style="text-align:center">Modèle humain face à une tâche. Millot</p>

 <br> <br> <br> <br>
Hardware --> "imposé" <!-- quel dimensionnement, Caractéristique physique (poids, filaire, etc.), quel capteurs..., Caractéristique commerciale : entreprise, prix,  : rendu dedans ou externe -->
 <br> 
 - quel dimensionnement (poids, taille, capteurs...)
 <br><br>
Casques (afficheurs)
 <!-- 2 hardwares casques -->
 <div class="container">
	<div class="table">
		<div class="table-header">
		<div class="header__item"><a>     </a></div>
			<div class="header__item"><a > Lunettes portables </a></div>
			<div class="header__item"><a >Casques milieux de gamme</a></div>
			<div class="header__item"><a >Casques haut de gamme + caves..</a></div>
		</div>
		<div class="table-content">	
			<div class="table-row">	
				<div class="table-data"> ...</div>			
				<div class="table-data">google card board, daydream; gearVR samsung...</div>
				<div class="table-data">oculus quest 2 ; htc vive pro eye ; HP omniceps reverb g2...</div>
				<div class="table-data">Varjo ; CAVE ; Simulateur...</div>
			</div>
			<div class="table-row">
				<div class="table-data"> pros </div>	
				<div class="table-data">prix, portable, dépendant portable</div>
				<div class="table-data">Fonctionnalités (captations, sans fils etc.)</div>
				<div class="table-data">top technologie</div>
			</div>
			<div class="table-row">
				<div class="table-data"> cons </div>	
				<div class="table-data"> écran partagé donc resolution /4;  reglage DIP ; ventilation ; ergonomie  </div>
				<div class="table-data">prix ; besoin ordinateur puissant</div>
				<div class="table-data">PRIX ; entretien ; SAV</div>
			</div>
			<div class="table-row">
				<div class="table-data"> Considérations </div>	
				<div class="table-data">developpement tous publics (divertir) plus sur l'application que sur la techno <br> uniquement portable IMU/gyroscope ; facile pour bluetooth ; bien pour petites app divertissements et services </div>
				<div class="table-data">Applications monde éco + Recherche (shs) <br> Utilisateurs communs à spécifiques</div>
				<div class="table-data">Usages très spécifiques (recherches sciences dures, R&D GG)</div>
			</div>
		</div>	
	</div>
</div>
<br><br>
  Liste des portables : https://developers.google.com/ar/devices#google_play 
  <br><br>
  Focus 3 casques "milieu de gamme"
    <br>
<div class="container">
	<div class="table">
		<div class="table-header">
		<div class="header__item"><a>     </a></div>
			<div class="header__item"><a > Oculus Quest 2 </a></div>
			<div class="header__item"><a > HTC Vive Pro Eye </a></div>
			<div class="header__item"><a > HP Omniceps reverb G2</a></div>
		</div>
		<div class="table-content">	
			<div class="table-row">	
				<div class="table-data"> Caractéristiques </div>			
				<div class="table-data"><a>Prix : 300€ <br> Cable : non</a> <br> Poids : 500g <br> FOV :104 horizontal 98 vertical <br> Résolution/oeil : 1834*1920 <br> Taux rafraichissement : 90hz <br> distance pupille : 58, 63 ou 68mm  </div>
				<div class="table-data">Prix : 1499€ <br> Cable : oui (adaptateur wifi) <br> Poids : 555g  <br> FOV : 106 horizontal  110 vertical <br> Résolution/oeil : 1440*1600  <br> Taux rafraichissement : 90hz <br> distance pupille : ajustable </div> 
				<div class="table-data">Prix : 1299€ <br> Cable : oui  <br> <a>Poids : 727</a>  <br> FOV : horizontal 98 vertical 90 <br> <a>Résolution/oeil : 2160*2160</a>  <br> Taux rafraichissement : 90 hz <br> distance pupille : ajustable </div> 
			</div>
			<div class="table-row">
				<div class="table-data"> Hardware  </div>	
				<div class="table-data">Processeur et RAM : Qualcomm Snapdragon XR2 - 6GB RAM <br> Ecran : LCD <br> Capteurs : 4 caméras et IMU <br> Système exploitation : <a>Android</a> <br>  </div>
				<div class="table-data"> Processeur et RAM : min Intel® Core™ i5-4590 GPU : NVIDIA® GeForce® GTX 97 4gb RAM <br> Ecran : amoled <br> Capteurs : <a>Stations (cameras infrarouges)</a>; IMU ; eyetracking  <br> Système exploitation : windows 10   <br>  </div>
				<div class="table-data"> Processeur et RAM : Intel Core i5, i7, Intel Xeon E3-1240 v5 GPU : NVIDIA GeForce GTX 1080 RAM: 8gb <br> Ecran : LCD  <br> Capteurs :4 caméras et IMU, eye tracking, <a>frequence cardiaque, face cam</a>  <br> Système exploitation : windows 10   <br>  </div>
			</div>
			<div class="table-row">
				<div class="table-data"> Consideration </div>	
				<div class="table-data">Facebook (compte requis) ; bien pour la majorité des situations (intérêt économique, et accessible sans pc performant); interaction mains </div>
				<div class="table-data">HP (?); A tester (capteurs interessants) </div>
				<div class="table-data">HTC (Valve - compte requis) ; Set-up un peu lourd  </div>
			</div>
		</div>	
	</div>
</div>


IHM physiques
 <br> <br> 
<br>Classiques (IMU, joystics, boutons, parole)
  <img src="contenu/controller.png"> </img>
<br>Embarquée (eyetracker, eeg, FC, facetracking, motion capture, gesture detection)
 <br> <br> 
  <img src="contenu/bci.png"> </img>
<br>A connecter... (haptique, non haptique, physiologique, biomécanique)
 <br> <br> 
  <img src="contenu/ultrason.jpg"> </img>
  <br>
  <img src="contenu/myo.jpg"> </img>
 <br>
 <br>
 <br>
 <br>
Software --> à vous de jouer !  Mais attention... voir conception <!--deployment, bibliothèques dispos ? latence, aide cognitives.. IHM...-->

 <!-- 3 software -->
  <br>
 <br>
 <br> Unity 3D 
<br>
 <br>
	intérêts : crossplatform, userfriendly, communauté
   <img src="contenu/unity.jpg"> </img>
   <br><br>

   <img src="contenu/unity2.jpg"> </img>

 
 <br><br>
	Blender : pour conception 3D
	<br><br>
	<img src="contenu/modeling.jpg"> </img>
	<img src="contenu/rigging.png"> </img>
	<img src="contenu/weighting.jpg"> </img>
	<img src="contenu/texturing.png"> </img>

	<br><br> Asset / banque modèles 3D (budget)
	<br><br>
	<img src="contenu/banque.jpg"> </img>
   
  
  
 Quelques bibliothèques 
 <br><br>
<img src="contenu/tobiisdk.jpg"> </img>

<br><br>

<img src="contenu/myounity.jpg"> </img>
<br><br>

<img src="contenu/bluetoothunity.jpg"> </img>

<br><br>

<img src="contenu/bitalinounity.jpg"> </img>

<br><br>

<img src="contenu/leapunity.jpg"> </img>
<br><br>

<img src="contenu/museunity.jpg"> </img>
 </p>
</li>
 
 
 
 
 
 
 
 <br><br><br><br>
 
    <li class='work'>
    <input class='radio' id='work12' name='works' type='radio' >
    <div class="relative">
      <label for='work12'>RV en SHS</label>
    </div>
 <p>
  <br><br><br><br>
    <!--R&D en SHS IHM -->

Démarche en R&D : 
<br> - Hypothèses 
<br> - Vérifier par expérimentations
<br>- Analyse -interprétation résultats = confirme ou infirme.

<br><br><br>
 

Domaines en SHS :
<br>
<br>- STAPS (physiologie - biomécanique - ergonomie, etc) 
<br>- Science cognitives (neuroscience - psychologies - etc) 
<br>- Sciences comportements (sociologie ; anthropologie, etc)
<br>
<br>Pas figé : 
<br>
<br>- Entrainement mental pour la performance : (STAPS et Science cognitive)
<br>- Marketing : versant cognitif + socio

<br>
<br>en IHM :
<br>
<br>- utilisation de la technologie avec un focus sur l'interaction (dans des buts d'optimisation pour un public cible) <!-- prenant donc en compte l'humain-->
<br>- Ergonomie cognitive
<br>- Ergonomie physique
<br><br>
<img src="contenu/HMI.png"> </img>

<br><br><br><br>
Exemples d'une recherche en SHS : Granem (Tourisme)
<br>
 <video class="vidL"; id="myVid24"controls><source src="contenu/granem.mp4" type="video/mp4"></video>  
<br><br>
<br> Hypothèse : Mise en situation impacte la consommation d'application de RV.
<br> Analyse : Variables Indépendantes --> Variables Dépendantes 
<br> Le chercheur souhaite expliquer --> permettent l'explication 

L'exemple des émotions dans cette étude (VD ou VI) ?
<br><br>

Quel signal pour caractériser l'émotion ressentie par un individu ?


<div class="container">
	<div class="table">
		<div class="table-header">
		<div class="header__item"> <a>Types d'analayse</a></div>
			<div class="header__item"><a >Comportementales </a></div>
			<div class="header__item"><a > Physiologiques</a></div>
			<div class="header__item"><a >Cognitives/Subjectif</a></div>
		</div>
		<div class="table-row">
				<div class="table-data"> Signaux </div>	
				<div class="table-data">capture mouvement (mocap, tracking expression faciale, accéléromètre, codage vidéo, etc.)</div>
				<div class="table-data">conductance, ecg, eeg</div>
				<div class="table-data">Self-report : questionnaires numérique ou papier (BdD)</div>
			</div>
		<div class="table-row">
				<div class="table-data"> Intérets </div>	
				<div class="table-data">Aspect dynamique, multisensoriel </div>
				<div class="table-data">Aspects dynamique, automatique </div>
				<div class="table-data">Interprétation</div>
			</div>
		<div class="table-row">
				<div class="table-data"> Biais </div>	
				<div class="table-data">Interprétation</div>
				<div class="table-data">Interprétation</div>
				<div class="table-data"> Mnésique, désirabilité sociale, etc</div>
			</div>
	</div>
</div>


  
 

 Importance de définir les besoins : 
 <br> <br>
 
  <img src="contenu/emotion.jpg"> </img>
  
<br> Quel signal, comment et qu'est ce qu'on récupère :
<br> - en fonction du contexte 1
<br> - possibilité d'interfaçage 2
<br> - eviter le surdimensionnement 3
<br><br>
 

 <p class="citation"; style="text-align:right">Littérature <br>1 Comment étudier les émotions en laboratoire.
<br>2 A Systemic Review of Available Low-Cost EEG Headsets Used for Drowsiness Detection.
<br>3 Emotion-Recognition Using Smart Watch Sensor Data: Mixed-Design Study.</p>


 </p>
</li>
 
<br><br><br><br>

  <li class='work'>
    <input class='radio' id='work13' name='works' type='radio' >
    <div class="relative">
      <label for='work15'>Conception</label>
<br>  <br>  <br> 
 
   <br><br>
   Conception centrée utilisateur 
   <br><br>
   
<br><br><br>Le choix du matériel, le choix des developpements sont fonction : 
<br>- des capacités (éco, developpement, matériel) 
<br> - des besoins (client) 
<br>- des UTILISATEURS

<br><br>
    <img src="contenu/UCD.png"> </img>
	<p class="citation"; style="text-align:center">Enhancing eco-safe driving behaviour through the use of in-vehicle human-machine interface: A qualitative study </p>
	
	<br><br>
    <img src="contenu/guide.gif"> </img>
	<p class="citation"; style="text-align:center">https://www.usability.gov/ </p>
	
	<br><br>
	Lean Start-up
   <img src="contenu/leanstartup.jpg"> </img>
	<p class="citation"; style="text-align:center">Innovation academy à Angers Technopole</p>
   
    <video class="vidL"; id="myVid25"controls><source src="contenu/lean.mp4" type="video/mp4"></video>  
  
   
   <br><br>
   Focus evaluation :
   <img src="contenu/UX.jpg"> </img>
   <br><br>
   <img src="contenu/UXeval.png"> </img>
   <br><br><br>
   - Echelle UX (pragmatique et hédonique)
   <img src="contenu/attrackdiff0.jpg"> </img>
   <img src="contenu/attrackdiff1.png"> </img>
   <img src="contenu/attrakdiff2.png"> </img>
   
   <br><br><br>
  - Echelle d'utilisabilité (pragmatique)
   <img src="contenu/sus.jpg"> </img>
	<img src="contenu/sus2.jpg"> </img>

    <br><br><br>
   
   
 <br> Lire la notice...
<br><embed src="contenu/OculusFrench_surbrillance.pdf" width=100% height=500px type='application/pdf'/>

<br> <br> Aspect santé : 
<br> - bléssures
<br> - crise epilpsie
<br> - problème occulaire (eye fatigue ; dryness (blink less when watching screens))
<br> <img src="contenu/ophtalmo.jpg"> </img>
<br> - Ergonomie (bon sens - posez vous des questions)
Ce qu'on ne peut pas : alléger un casque VS ce qu'on peut réel ou virtuel (limiter temps, position confortable, limiter mvt tête)
<br>Est-ce que la personne porte des lunettes ? 
<br>Est-elle réfractère aux technos ? 

<br>- Dépendance, immaginaire (dev psycho) et developpement cognitif (<13ans)

<br> <img src="contenu/children.jpg"> </img>

<br> Aspect ethique (données physio)

<br> <img src="contenu/privacy.jpg"> </img>



<br><br>

 <br> MOTION SICKNESS !
  <br> Diagnostique (conséquences) --> general discomfort, headache, stomach awareness, nausea, vomiting, pallor, sweating, fatigue, drowsiness, disorientation, and apathy

  <br><br>Pas tous égaux (cause interpersonnelle) ?
 <br> <img src="contenu/womensickness.jpg"> </img>
 
 <br><br> A votre niveau (cause intrapersonnelle) - Incohérences sensorielles
 <br> Incohérences bénéfiques --> mieux simuler / immergé un ev en trompant les sens (p.ex. son spatialisé - deplacement par vection).
     <video class="vidL"; id="myVid26"controls><source src="contenu/vection.mp4" type="video/mp4"></video>  

 
 
 <br> Incohérences perturbatrices --> cybersikness (95% des soucis) : 
 <br> - Latence < 20ms
 <br>- FPS >30
 <br> - Eviter mouvements synueux 
 <br>- Utiliser des vitesses de déplacement connues (marche à 4kmh - course 12-15kmh) 
 <br>- Eviter accélérations longues + brusques et à répétitions + variables  (<2ms et durant quelques s)
 <br>- Perception du mouvement plus sensible en périphérie --> flouter la périphérie lors des déplacements importants ou sinueux (diminue l'immersion)
 <br>- Téléportation : bref écran noir ou cinématique très bien pensée
 <br> <br> <img src="contenu/incoherence.jpg"> </img>
	<p class="citation"; style="text-align:center">Synthèse des solutions à envisager pour traiter les trois principales incohérences sensorimotrices. <br> Les casques de réalité virtuelle et de jeux vidéos. Ph Fuchs</p>

 <br>  <br> 
</p>
</li>

<p>
Concept de la transparence (rejoint l'utilisabilité)
<br>
<br> IHM doit se faire oublier par l’utilisateur --> très important en vr !
<br> Pas besoin de réfléchir mais peut necessiter un petit temps d'adaptation voir une phase d'apprentissage.
<br>
<br> Exo : votre application necessite d'attraper / interagir avec un objet au loin.
<br> Vous avez un quest 2 et pouvez connecter n'importe quelle interface en bluetooth.
</p>
     <li class='work'>
    <input class='radio' id='work14' name='works' type='radio' >
    <div class="relative">
      <label for='work14'; style="font-size: 1vw;" >Réponse</label>
    </div>
	
    <div class='content'>
      <p>
 
<br> Aide cognitive et intention de l'utilisateur : 
<br> - Raycast (à partir d'une certaine distance) + focus dans une zone
<br> - Objet en surbrillance, en control d'une autre couleur, etc
<br> - Guider le deplacement - objet se pose automatiquement sur les surfaces

<video class="vidL"; id="myVid27"controls><source src="contenu/exo.mp4" type="video/mp4"></video>  
</p>
</div>
</li>

 <br> <br>

 <li class='work'>
    <input class='radio' id='work15' name='works' type='radio' >
    <div class="relative">
      <label for='work15'>En pratique</label>
<br>  <br>  <br>  <br>  
<p>
<br> Obligatoire --> Formulaire de consentement OBLIGATOIRE ! 
<br> - Informant des risques, des tenants et aboutissants de l'étude
<br> - Possibilité d'arrêter sans donner d'explication
<br> - Qu'est-ce qu'on récupère comme données et à quoi elles vont servir

<br><br> Facultatif (mais vivement conseillé) : 
<br> - Servez vous des outils de la littérature : utilisabilité, UX, ergonomie physique, ergonomie cognitive
<br> - Prennez vos projets/innovations d'un point de vue holistique/multifactoriel (ce que vous avez, ce que veulent vos clients, les utilisateurs) avec au centre l'humain
<br> - Analyser les besoins de votre application : réfléchissez aux interfaces -> existent-elles, faut il tout simuler, faut il créer une interface personnalisée ?
<br>- Questionnez-vous - Ayez un peu d'empathie - Utiliser votre bon sens - Soyez critique sur ce qu'on vous demande - Communiquez !
<br><br><br><br><br>

</p>
</div>
</li>



 

 </ul>
 Merci de votre attention !
</div>  
 </div>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
<!-- Javascript  -->
<script>
for (let pas = 1; pas < 100; pas++) {
document.getElementById("myVid"+pas).addEventListener("mouseover", function() {
	this.play();
});

document.getElementById("myVid"+pas).addEventListener("mouseleave", function() {
	this.pause();
});
}

function myFunction() {
for (let pas = 1; pas < 100; pas++) {
  var x = document.getElementById("myDIV"+pas);
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
}


</script>
</body>
</html>
